{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5822ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f54689",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_PATH = \"indexes/reference.index\"\n",
    "META_PATH = \"indexes/chunks_metadata.pkl\"\n",
    "CONFIG_PATH = \"indexes/index_config.json\"\n",
    "BM25_PATH = \"indexes/bm25.pkl\"\n",
    "\n",
    "with open(BM25_PATH, \"rb\") as f:\n",
    "    bm25 = pickle.load(f)\n",
    "\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    chunked_docs = pickle.load(f)\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "embedder = SentenceTransformer(config[\"embedding_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"LLM_HW_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API Key not set\")\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "model = client.models\n",
    "model_name = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"indexes/documents.pkl\", \"rb\") as f:\n",
    "    documents = pickle.load(f)\n",
    "\n",
    "print(\"Loaded\", len(documents), \"documents from corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlagiarismResult(BaseModel):\n",
    "    verdict: Literal[0, 1] = Field(\n",
    "        description=\"Return 1 if the code is Plagiarized (or derived). Return 0 if it is Original.\"\n",
    "    )\n",
    "    explanation: str = Field(\n",
    "        description=\"A brief explanation referencing specific retrieved files if plagiarism is found.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_embedding(\n",
    "    code_snippet: str,\n",
    "    top_k: int = 5,\n",
    "    plagiarism_threshold: float = 0.42\n",
    "):\n",
    "\n",
    "    query_embedding = embedder.encode(\n",
    "        [code_snippet],\n",
    "        normalize_embeddings=True\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "    D, I = index.search(query_embedding, top_k)\n",
    "\n",
    "    results = []\n",
    "    max_sim = float(np.max(D[0]))\n",
    "\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        meta = chunked_docs[idx]\n",
    "\n",
    "        results.append({\n",
    "            \"similarity\": float(score),\n",
    "            \"file_name\": meta[\"file_name\"],\n",
    "            \"chunk_type\": meta[\"chunk_type\"],\n",
    "            \"matched_text_preview\": meta[\"text\"][:300]\n",
    "        })\n",
    "\n",
    "    plagiarism = max_sim >= plagiarism_threshold\n",
    "\n",
    "\n",
    "    if max_sim >= plagiarism_threshold:\n",
    "        verdict = 1\n",
    "    else:\n",
    "        verdict = 0\n",
    "\n",
    "    return {\n",
    "        \"plagiarism\": plagiarism,\n",
    "        \"max_similarity\": round(max_sim, 4),\n",
    "        \"verdict\": verdict,\n",
    "        \"matches\": results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8842104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_llm(student_code: str):\n",
    "    \"\"\"\n",
    "    Direct LLM Analysis: Dumps the whole repo + student code into the prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus_texts = []\n",
    "    for doc in documents:\n",
    "        fname = doc.get('file_name', 'unknown_file')\n",
    "        content = doc.get('raw_code', doc.get('text', '')) \n",
    "        corpus_texts.append(f\"--- START FILE: {fname} ---\\n{content}\\n--- END FILE ---\\n\")\n",
    "    \n",
    "    full_repo_context = \"\\n\".join(corpus_texts)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a code plagiarism detection system.\n",
    "    \n",
    "    RETRIEVED REFERENCE \\CODE:\n",
    "    {full_repo_context}\n",
    "    \n",
    "    SUSPICIOUS STUDENT CODE:\n",
    "    {student_code}\n",
    "    \n",
    "    TASK:\n",
    "    Compare the logic of the Student Code against the Reference Code.\n",
    "    - If the student code is a clear derivative (same logic, renamed variables, reordered lines), return verdict 1.\n",
    "    - If the student code uses a different algorithm or logic, return verdict 0.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "                model=model_name,\n",
    "                contents=prompt,\n",
    "                config={\"response_mime_type\": \"application/json\", \"response_json_schema\": PlagiarismResult.model_json_schema(),}\n",
    "        )\n",
    "\n",
    "        structured_output = PlagiarismResult.model_validate_json(response.text) # type: ignore\n",
    "        \n",
    "        result = structured_output.model_dump()\n",
    "        \n",
    "        result[\"retrieved_chunks\"] = retrieved_chunks\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"RAG Error: {e}\")\n",
    "        # Fallback structure so your eval loop doesn't crash (TBH I do not like this result cause if it crashed we are just saying that it was not plagiarism)\n",
    "        return {\n",
    "            \"verdict\": 0, \n",
    "            \"explanation\": f\"Error during processing: {str(e)}\",\n",
    "            \"retrieved_chunks\": retrieved_chunks\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_rag(\n",
    "    student_code: str,\n",
    "    top_k: int = 5,\n",
    "):\n",
    "    query_emb = embedder.encode([student_code], normalize_embeddings=True).astype(\"float32\")\n",
    "    \n",
    "    D, I = index.search(query_emb, top_k)\n",
    "    \n",
    "    retrieved_chunks = []\n",
    "    context_texts = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        meta = chunked_docs[idx]\n",
    "        code_text = meta.get(\"original_code\", meta[\"text\"])\n",
    "        retrieved_chunks.append({\n",
    "            \"similarity\": float(score),\n",
    "            \"file_name\": meta[\"file_name\"],\n",
    "            \"chunk_type\": meta[\"chunk_type\"],\n",
    "            \"matched_text\": code_text\n",
    "        })\n",
    "        context_texts.append(f\"File: {meta['file_name']}\\n{meta.get('original_code', meta['text'])}\\n\")\n",
    "    \n",
    "    context = \"\\n\".join(context_texts)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a code plagiarism detection system.\n",
    "    \n",
    "    RETRIEVED REFERENCE CODE:\n",
    "    {context}\n",
    "    \n",
    "    SUSPICIOUS STUDENT CODE:\n",
    "    {student_code}\n",
    "    \n",
    "    TASK:\n",
    "    Compare the logic of the Student Code against the Reference Code.\n",
    "    - If the student code is a clear derivative (same logic, renamed variables, reordered lines), return verdict 1.\n",
    "    - If the student code uses a different algorithm or logic, return verdict 0.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "                model=model_name,\n",
    "                contents=prompt,\n",
    "                config={\"response_mime_type\": \"application/json\", \"response_json_schema\": PlagiarismResult.model_json_schema(),}\n",
    "        )\n",
    "\n",
    "        structured_output = PlagiarismResult.model_validate_json(response.text) # type: ignore\n",
    "        \n",
    "        result = structured_output.model_dump()\n",
    "        \n",
    "        result[\"retrieved_chunks\"] = retrieved_chunks\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"RAG Error: {e}\")\n",
    "        # Fallback structure so your eval loop doesn't crash (TBH I do not like this result cause if it crashed we are just saying that it was not plagiarism)\n",
    "        return {\n",
    "            \"verdict\": 0, \n",
    "            \"explanation\": f\"Error during processing: {str(e)}\",\n",
    "            \"retrieved_chunks\": retrieved_chunks\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hybrid_rag(\n",
    "    student_code: str,\n",
    "    top_k: int = 5,\n",
    "):\n",
    "    query_emb = embedder.encode([student_code], normalize_embeddings=True).astype(\"float32\")\n",
    "\n",
    "    D, I = index.search(query_emb, k=top_k) \n",
    "    \n",
    "\n",
    "    dense_ranks = {idx: rank for rank, idx in enumerate(I[0])}\n",
    "    \n",
    "\n",
    "    tokenized_query = re.findall(r\"\\w+\", student_code.lower())\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    sparse_indices = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "    sparse_ranks = {idx: rank for rank, idx in enumerate(sparse_indices)}\n",
    "    \n",
    "    fused_scores = {}\n",
    "    \n",
    "    all_candidates = set(dense_ranks.keys()).union(set(sparse_ranks.keys()))\n",
    "    \n",
    "    k_constant = 60\n",
    "    for idx in all_candidates:\n",
    "        rank_dense = dense_ranks.get(idx, 100)\n",
    "        rank_sparse = sparse_ranks.get(idx, 100)\n",
    "        \n",
    "        fused_scores[idx] = (1 / (k_constant + rank_dense)) + (1 / (k_constant + rank_sparse))\n",
    "\n",
    "    top_indices = sorted(fused_scores, key=fused_scores.get, reverse=True)[:top_k] # type: ignore\n",
    "    \n",
    "\n",
    "    retrieved_chunks = []\n",
    "    context_texts = []\n",
    "    for idx in top_indices:\n",
    "        if idx < len(chunked_docs):\n",
    "            meta = chunked_docs[idx]\n",
    "            retrieved_chunks.append({\n",
    "                \"file_name\": meta[\"file_name\"],\n",
    "                \"chunk_type\": meta[\"chunk_type\"],\n",
    "                \"rrf_score\": float(fused_scores[idx]), # Save fusion score\n",
    "                \"matched_text\": meta.get(\"original_code\", meta[\"text\"])\n",
    "            })\n",
    "            context_texts.append(f\"File: {meta['file_name']}\\n{meta.get('original_code', meta['text'])}\\n\")\n",
    "    \n",
    "\n",
    "    context = \"\\n\".join(context_texts)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a code plagiarism detection system.\n",
    "    \n",
    "    RETRIEVED REFERENCE CODE:\n",
    "    {context}\n",
    "    \n",
    "    SUSPICIOUS STUDENT CODE:\n",
    "    {student_code}\n",
    "    \n",
    "    TASK:\n",
    "    Compare the logic of the Student Code against the Reference Code.\n",
    "    - If the student code is a clear derivative (same logic, renamed variables, reordered lines), return verdict 1.\n",
    "    - If the student code uses a different algorithm or logic, return verdict 0.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "                model=model_name,\n",
    "                contents=prompt,\n",
    "                config={\"response_mime_type\": \"application/json\", \"response_json_schema\": PlagiarismResult.model_json_schema(),}\n",
    "        )\n",
    "\n",
    "        structured_output = PlagiarismResult.model_validate_json(response.text) # type: ignore\n",
    "        \n",
    "        result = structured_output.model_dump()\n",
    "        \n",
    "        result[\"retrieved_chunks\"] = retrieved_chunks\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"RAG Error: {e}\")\n",
    "        # Fallback structure so your eval loop doesn't crash (TBH I do not like this result cause if it crashed we are just saying that it was not plagiarism)\n",
    "        return {\n",
    "            \"verdict\": 0, \n",
    "            \"explanation\": f\"Error during processing: {str(e)}\",\n",
    "            \"retrieved_chunks\": retrieved_chunks\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
